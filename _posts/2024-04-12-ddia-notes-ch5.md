---
layout: post
title: DDIA阅读笔记(5)：分布式数据系统的复制
date: 2024-04-12 +0800
tags: [系统设计, DDIA]
categories: [系统设计]
---

## 分布式数据系统简介

### 为什么要把数据分布到多台机器上？

- 可伸缩性
    如果数据量、读取负载、写入负载超出了单台机器的处理能力，就需要把负载分散到多台机器上。
    
- 高可用性
    使用多台机器可以提供冗余，在单台机器出现故障的情况下还能继续提供服务。

- 低延迟
    如果在世界各地都有用户，可以在全球范围内部署多个服务器，从而每个用户都可以从最近的服务器获取服务。

### 分布式数据系统的架构

分布式数据系统使用无共享架构（shared-nothing architecture），运行数据库软件的每台机器或虚拟机称为节点（node）。

每个节点只使用自己的处理器、内存和磁盘，节点之间的协调是在软件层面使用网络实现的。

### 怎么把数据分布到多个节点上？

有两种常见的方式：

- 复制（Replication）

在几个不同的节点上保存数据的相同副本，从而提供冗余。如果一些节点不可用，剩余的节点还可以提供数据服务。

- 分区（Partitioning）

把一个大型数据库拆分成较小的子集，称为分区（partitions）。把不同的分区指派给不同的节点，称为分片（sharding）。

复制和分区经常同时使用，如下图所示，一个数据库被拆分成两个分区，每个分区有两个相同的副本。

![DistributedData ReplicationAndPartitioning](/assets/img/DDIA_DistributedData_ReplicationAndPartitioning.png)

## 领导者与追随者

副本（replica）: 存储了数据库拷贝的每个节点。每次向数据库的写入操作都需要传播到所有副本，否则就会出现数据不一致。

最常见的解决方案是基于领导者的复制（leader-based replication），也叫主从复制（master/slave replication），原理如下：

![DistributedData MasterSlaveReplication](/assets/img/DDIA_DistributedData_MasterSlaveReplication.png)

- 领导者（leader）：将一个副本指定为领导者，也称主库（master）。当客户端向数据库写入时，必须把请求发给领导者，它会把新数据写入本地存储。
- 追随者（followers）：其他副本都是追随者，也称从库（slaves）。每当领导者把新数据写入本地存储时，也会把数据变更发送给所有追随者，让他们能相应地更新其本地数据库副本。
- 只有领导者才能接受写入操作，领导者和追随者都可以接受读取操作。

### 同步复制 VS. 异步复制

如下所示，假设系统有一个主库和两个从库。在某个时间点，用户向主库发送了更新个人头像的请求；过了一会儿，主库将数据变更发送给两个从库；最后，在从库1响应成功后，主库通知用户更新成功。

![DistributedData SyncAndAsyncReplication](/assets/img/DDIA_DistributedData_SyncAndAsyncReplication.png)

- 同步复制：从库1的复制是同步的，因为主库会等到从库1写入成功后，再通知用户写入成功。
- 异步复制：从库2的复制时异步的，因为主库不会等待从库2的响应。

通常情况下，复制的速度是非常快的，大部分数据库系统能在1秒内完成从库的同步。然而，无法提供复制用时的保证，因为会有很多特殊情况，比如：从库可能处于故障恢复中、节点间存在网络问题等。

同步复制和异步复制的对比:

| 复制方式 | 优点  | 缺点  |
| --- | --- | --- |
| 同步复制  | 保证从库有和主库一致的最新数据副本，如果主库突然失效，仍然可以在从库中获取数据。 | 如果从库没有响应（比如崩溃、有网络问题），主库就无法处理写入操作。 |
| 异步复制  | 从库失效不会影响主库继续处理写入。 | 弱化的持久性：如果主库失效且不可恢复，那么任何还没复制给从库的写入都会丢失。这意味着即使向客户端确认成功了，写入也无法保证是持久的（durable）。 |

在实际使用中，如果在数据库上启用同步复制，通常只有一个从库是同步的，其他从库还是异步的。如果同步从库变得不可用或者很慢，就把另一个异步从库改成同步。这种方式也被称为半同步，可以保证至少在两个节点上有最新的数据副本。

异步复制虽然会导致弱化的持久性，但是使用很广泛。

### 如何建立新从库？

为了增加副本的数量，或者替换失败的节点，我们需要建立新的从库。在客户端会不断向数据库写入数据的情况下，如何保证新从库拥有主库数据的精确副本呢？

锁定数据库使其无法写入是不可取的，因为这会影响数据库的高可用。

以下是一种不需要停机的设立新从库的方式：

1. 在某个时刻获取主库的一致性快照。
2. 把快照复制到新从库。
3. 把从库连接到主库，并拉取快照之后的所有数据变更。
4. 当从库处理完快照之后的所有数据变更，我们就说它赶上了（caught up）主库。

### 如何处理节点宕机？

系统中的任何节点都可能宕机，可能是因为意外故障，也可能是因为计划内的维护（如系统升级）。

为了实现高可用，需要保证即使个别节点宕机，也能保持整个系统的运行。

#### 从库失效：追赶恢复

从库会在本地磁盘上记录从主库收到的数据变更。如果从库崩溃并重启了，可以从日志中知道故障前处理的最后一个事务，然后从主库请求之后的所有数据变更。

#### 主库失效：故障切换

如果主库失效了，需要把一个从库提升为新的主库，然后重新配置系统来启用新主库。这个过程称为故障切换（failover）。

故障切换分为手动和自动。自动的故障切换包括以下步骤：
1. 确认主库失效。
    可以简单地根据超时（timeout）来判断，如果一个节点在一段时间内没有响应，就认为它挂了。

2. 选择一个新主库。
    可以通过剩余副本选举产生新主库，或者由选定的控制器节点（controller node）来指定新主库。

3. 重新配置系统来启用新主库。
    - 客户端需要把写操作发送到新主库。
    - 其他从库需要从新主库拉取请求。
    - 旧主库恢复后需要意识到新主库的存在，并成为一个从库。

### 如何实现复制？

#### 基于语句的复制

主库记录下执行的每个写入请求（即语句，statement），并把语句日志发送给从库，从库再执行相应的操作。

这种复制方式有以下问题：
- 如果使用了非确定性函数（nondeterministic），例如`NOW()`和`RAND()`，可能会在每个副本上生成不同的值。
- 如果使用了自增列（auto increment），或者依赖于数据库中现有数据进行更新，那么必须保证在每个副本上按照完全相同的顺序执行语句，否则会产生不同的值。
- 如果语句有副作用，例如触发器和存储过程，可能会在每个副本上产生不同的副作用。

有办法可以绕开这些问题，但是由于边缘情况太多了，现在通常不会采用这种复制方式。

#### 基于预写式日志的复制

预写式日志（Write Ahead Log, WAL）是包含了所有数据库写入的仅追加字节序列。主库通过网络把预写式日志传输给从库，然后从库就可以根据日志来构建副本了。

这种复制方式的问题在于，预写式日志记录的数据非常底层——哪些磁盘块的哪些字节发生了更改。这会导致复制与存储引擎紧密耦合，从而导致主库和从库必须运行相同版本的数据库软件。

这对运维是十分不利的。如果复制协议允许从库使用比主库新的软件版本，就可以先升级从库，再执行故障切换，使升级后的从库之一成为新的主库，从而实现零停机升级。否则，升级就必须要停机。

#### 基于逻辑日志的复制（基于行）

为了避免预写式日志的缺点，可以对复制和存储引擎使用不同的日志格式，从而使复制日志和存储引擎解耦。这种复制日志称为逻辑日志（logical log）。

逻辑日志通常以行的粒度来描述写入记录：
- 对于插入的行，日志包含所有列的值。
- 对于删除的行，日志包含能唯一标识行的信息，例如主键。
- 对于更新的行，日志包含能唯一标识行的信息，以及所有列的新值。

使用逻辑日志进行复制，可以使主库和从库运行不同版本的数据库软件，甚至不同的存储引擎，从而十分方便运维。

#### 基于触发器的复制

上面的三种复制方法都是由数据库系统实现的，不涉及应用程序代码。

触发器允许在数据更改发生时，自动执行自定义的应用程序代码。在自定义代码中，可以把更改写入到一个单独的表中，然后再使用外部程序读取这个表，把数据变更复制到另一个系统。

基于触发器的复制通常比其他复制方式的开销更大，也更容易出错，但是它更灵活。

## 复制延迟问题

在web应用中，读多写少是一种常见的场景，基于领导者的复制就适用于这种场景，所有的写请求都由单个节点处理，但读请求可以由任意一个副本处理。

从库通常是异步复制的，否则单个节点故障会导致整个系统都无法写入。当从异步从库读取数据时，如果从库落后，就会返回过时的信息。这个问题叫做数据不一致，即同时从主库和从库执行相同的查询，得到的结果却不一致。

这种数据不一致的问题只是暂时的，如果停止写入数据库一段时间，从库最终会赶上主库。这种效应被称为最终一致性（eventual consistency）。从库落后的时间是不固定的，有可能是毫秒，也可能是秒，甚至分钟。

### 读己之写

如图所示，用户在写入后就立马查看数据，由于新数据还没到达副本，从用户的角度好像数据没提交成功。

![DistributedData ReadAfterWrite](/assets/img/DDIA_DistributedData_ReadAfterWrite.png)

这种场景需要保证写后读一致性（read-after-write consistency），即用户刷新页面后，总能看到自己提交的任何更新。对其他用户没有这种保证，其他用户可能过一会儿才能看到该用户的更新。

写后读一致性的实现方式包括：
- 对于用户可能修改过的内容，总是从主库读取。例如，用户查看自己的个人资料时查询主库，查看别人的个人资料时查询从库。
- 如果应用中的大部分内容都可能被用户修改，那么总是从主库查询是不行的，会破坏读伸缩性。这个时候可以用其他标准来决定是否从主库读取，例如：
    - 跟踪上次更新的时候，在上一次更新后的一分钟内，从主库读取。
    - 监控从库的复制延迟，如果从库滞后了超过一分钟，就不再向该从库读取。
- 记录最近一次写入的时间戳，保证从库必须有该时间戳之前的所有变更，才能处理用户的读取请求。否则，要么等该从库追上来，要么换一个从库来处理。

如果副本分布在多个数据中心，或者同一用户从多个设备请求服务，情况会更加复杂。

### 单调读

如图所示，用户2345进行了两次相同的查询，第一次从延迟较小的从库读取，返回了用户1234新添加的评论，第二次从延迟较大的从库读取，却没有返回新评论。从用户2345的角度，明明看见了新评论，突然又消失了，可能会很困惑。

![DistributedData MonotonicReads](/assets/img/DDIA_DistributedData_MonotonicReads.png)

这种场景需要保证单调读（monotonic reads），即当用户顺序地进行多次读取时，不会看到时光倒流（moving backward in time）。

一种实现单调读的方式是，确保一个用户的读取请求总是由同一个从库来处理。例如，可以基于用户ID进行散列，然后选择从库。

### 一致前缀读

如图所示，用户Mr.Poons和用户Mrs.Cake的提问和回答分别写到了不同的分区中，对用户Observer来说，好像Mrs.Cake在Mr.Poons提问之前就回答了问题一样，令人疑惑。

![DistributedData ConsistentPrefixReads](/assets/img/DDIA_DistributedData_ConsistentPrefixReads.png)

这种场景下需要保证一致前缀读（consistent prefix reads），即如果一系列写入按照某个顺序发生，那么任何人在读取这些写入时，也会看到它们按照同样的顺序出现。

一种实现一致前缀读的方式是，确保任何因果相关的写入都写入到相同的分区。如果无法这样实现，也可以采用一些显式跟踪因果依赖关系的算法。

## 多主复制

单主复制的主要缺点是，如果唯一的主库挂了，就无法向数据库写入了。为了避免这个问题，可以让多个节点接受写入，这种方式称为多主复制（master-master replication）。

在多主复制系统中，处理写入的主库需要把数据变更转发给其他所有节点，包括其他主库。

### 应用场景

#### 多个数据中心

如图所示，对于副本分散在多个数据中心的数据库，每个数据中心都有一个主库。在数据中心内部，使用主从复制；在数据中心之间，主库之间互相复制。

![DistributedData MultiMasterInMultiDatacenter](/assets/img/DDIA_DistributedData_MultiMasterInMultiDatacenter.png)

在多个数据中心的系统中，多主比单主更好的原因是：

- 性能更好
    在单主配置中，所有写入操作都必须通过互联网进入唯一的主库所在的数据中心，网络延迟可能会比较高。在多主配置中，每个写入操作都可以在本地数据中心处理，然后与其他数据中心异步复制，用户感受到的网络延迟会更低。

- 可以容忍数据中心停机和网络问题
    在单主配置中，一旦主库所在的数据中心停机或者出现网络问题，就会影响到所有的写入操作。在多主配置中，一个数据中心挂了，不会影响其他数据中心。

#### 需要离线操作的客户端

如果一个应用程序支持多端使用，并且支持在断网后继续工作，例如日历应用，那么就需要考虑多主复制。

当某一个设备断网时，依然需要在该设备上新建和查看会议，此时就需要在每个设备上都有一个充当主库的本地数据库，接受读写请求。当设备恢复联网时，再异步复制到服务器和其他设备。

#### 实时协作编辑的应用程序

实时协作编辑的应用程序允许多个人同时编辑文档，例如Google Docs。每个用户编辑时，所作的更改都会立刻应用到本地副本中，再异步复制到服务器和其他用户。

### 处理写入冲突

多主复制最大的问题是写冲突。如下所示，用户1和用户2通过不同的主库分别修改了同一个页面的标题，异步复制时却发现有冲突。

![DistributedData MultiMasterConflict](/assets/img/DDIA_DistributedData_MultiMasterConflict.png)

在单主系统中，如果同时有两个写入，第二个写入会被阻塞，直到第一个写入完成。一旦发生冲突，第二个写入的用户立刻就能知道并解决。

在多主系统中，两个写入都是成功的，只有在之后的复制过程中，才能异步检测到冲突，这时已经没办法要求用户来解决冲突了。

#### 避免冲突

处理冲突最简单的方式是避免冲突。例如，在一个用户可以编辑自己资料的应用程序中，确保一个用户的所有写入请求都被路由到同一个数据中心，由该数据中心的主库处理。

#### 收敛至一致的状态

在多主系统中，数据库必须以一种收敛（convergent）的方式解决冲突，使所有副本在所有变更复制完成时收敛到一个相同的值。

解决冲突的方式包括：
- 给每个写入一个唯一的ID，如时间戳、长随机数、UUID、键和值的哈希等，挑选最大ID作为最终值，并丢弃其他写入。
    - 如果使用时间戳作为ID，则称为最后写入胜利（LWW，last write wins）
    - 这种方式很流行，但是可能会造成数据丢失
- 给每个副本分配一个唯一的ID，ID越大的副本中的写入具有越高的优先级。
    - 可能会造成数据丢失
- 以某种方式把这些值合并，作为最后的结果，例如`B/C`。
- 记录冲突，并让应用程序代码来解决冲突。
    - 写时执行：只要数据库系统检测到冲突，就调用冲突处理程序。
    - 读时执行：存储所有冲突写入，等到下一次读取再处理，可以提示用户或自动解决冲突，并把结果写回数据库。

### 复制拓扑

复制拓扑（replication topology）表示写入操作从一个节点传播到另一个节点的通信途径。如下所示，有三种常见的复制拓扑：

![DistributedData ReplicationTopology](/assets/img/DDIA_DistributedData_ReplicationTopology.png)

- 环形拓扑（circular topology）：每个节点都从一个节点接收写入，并把这些写入和自己的写入一起转发给另一个节点。
- 星形拓扑（star topology）：一个指定的根节点把写入转发给其他节点。可以推广到树。
- 全部到全部拓扑（all-to-all topology）：每个节点都把写入转发给其他所有节点。

为了防止无限复制循环，每次复制都会记录经过的所有节点的标识符，当一个节点收到包含自己标识符的数据更改时，就忽略这个更改。

环形和星形拓扑的缺点是，如果一个节点发生故障，可能会中断其他节点之间的复制消息流。全部到全部拓扑的容错性更好，因此最为常用。

## 无主复制

在无主复制系统中，没有主库的概念，允许任何副本接受来自客户端的写入。

在一些无主复制系统中，客户端直接把写入发送到几个副本中。在另一些系统中，有一个协调者（coordinator）节点来代表客户端进行写入。

### 节点故障时写入数据库

如下所示，无主数据库中有三个副本，其中一个副本不可用。客户1234把写入并行发送到所有副本，其中两个可用副本响应成功，不可用副本无响应。由于三个副本中的两个都写入成功了，客户就认为这次写入成功了。

过了一会，不可用副本重新上线了，但是其中的有些数据还是旧的值。这时，客户2345向所有副本发送读取请求，其中两个副本返回了最新值，一个副本返回了旧的值。通过对比版本号，客户可以确定哪个值是最新的，从而读取最新值。

![DistributedData LeaderlessExample](/assets/img/DDIA_DistributedData_LeaderlessExample.png)

#### 不可用副本重新上线后，怎么赶上那些错过的写入呢？

有两种常见机制：

1. 读修复（read repair）

    当客户端并行读取多个副本时，可以检测到哪些副本还是旧的值，然后把最新值写回到这些副本。这种方法适用于读频繁的场景。

2. 反熵过程（anti-entropy process）

    通过后台进程，不断查找副本之间的数据差异，并把最新值从一个副本复制到另一个副本。

#### 在一个无主数据库中，有多少个副本确认才能认为写入成功呢？

假设一个无主数据库有n个副本，每个写入必须由w个副本确认才能认为是成功的，每个读取必须从r个副本查询。

如果`w + r > n`，那么读取时r个副本中至少会有一个副本的值是最新的，读取时一定能获得最新的值。满足这个条件的r和w称为读写的法定人数（quorum）。

一种常见的配置方式是，让n为奇数，并设置`w = r = (n+1)/2 (向上取整)`。

### 法定人数的局限性

即使满足`w + r > n`，依然可能出现读取到旧值的情况：

1. 如果两个写入同时发生，都只反应在某些副本上，那么读取时无法确定挑选哪个是最新值。
2. 如果读和写同时发生，写操作只反映在某些副本上，那么无法确认读取返回的是新值还是旧值。
3. 如果写操作失败了，但是没有把写入成功的副本回滚，那么读取时仍然可能会读到这次失败写入的值。
4. 如果带有新值的副本发生故障，需要从带有旧值的副本进行恢复，那么存储新值的副本数会打破法定人数的条件。

### 宽松的法定人数和提示移交

在一个大型的集群中，节点数量大于n，网络中断导致客户端无法连接到值所在的n个节点，但可以连接到其他节点。此时需要权衡：对于无法达到法定人数的写入，返回错误更好呢，还是允许它们写入到可达的节点？

后者称为宽松的法定人数（sloppy quorum）：写和读仍然需要w和r个成功的响应，但这些响应可以来自指定的n个节点之外的其他节点。

一旦网络恢复了，一个节点代表另一个节点临时接受的写入会被发送到适当的节点，称为提示移交（hinted handoff）。

宽松的法定人数可以提高写入的可用性，但是会导致读取时，即使满足`w + r > n`，依然可能出现读取到旧值，除非提示移交已经完成。